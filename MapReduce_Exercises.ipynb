{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Thiết lập môi trường Spark**\n",
    "\n",
    "**Mục tiêu:**\n",
    "1. Import tất cả các thư viện cần thiết cho các bài toán.\n",
    "2. Khởi tạo `SparkSession` một lần duy nhất để tất cả các bài toán bên dưới có thể tái sử dụng. Việc này giúp tối ưu hóa hiệu suất, tránh lãng phí tài nguyên do phải khởi tạo và dừng Spark nhiều lần."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import math\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Khởi tạo SparkSession duy nhất cho toàn bộ notebook\n",
    "spark = SparkSession.builder.appName(\"MapReduceExercises\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Bài 1: Tìm số lớn nhất**\n",
    "\n",
    "**Các bước thực hiện:**\n",
    "- **Dữ liệu đầu vào:** Tệp `phantichdulieu/songuyen.txt`.\n",
    "- **Các bước tính toán:**\n",
    "  1. Đọc tệp thành RDD.\n",
    "  2. `flatMap` để tách dòng thành các số.\n",
    "  3. `map` để chuyển chuỗi thành số nguyên.\n",
    "  4. `max()` để tìm giá trị lớn nhất.\n",
    "- **Kết quả trả về:** Số nguyên lớn nhất."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_b1 = sc.textFile(\"phantichdulieu/songuyen.txt\")\n",
    "numbers_str_rdd = rdd_b1.flatMap(lambda line: line.split(' '))\n",
    "numbers_int_rdd = numbers_str_rdd.filter(lambda x: x != '').map(lambda x: int(x))\n",
    "max_number = numbers_int_rdd.max()\n",
    "print(f\"Số lớn nhất tìm được là: {max_number}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Giải thích kết quả**\n",
    "\n",
    "Chương trình đã đọc, xử lý và tìm ra giá trị số nguyên lớn nhất từ tệp `songuyen.txt`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Bài 2: Đếm số lần xuất hiện của một xâu**\n",
    "\n",
    "**Các bước thực hiện:**\n",
    "- **Dữ liệu đầu vào:** Tệp `phantichdulieu/HXH.txt`.\n",
    "- **Các bước tính toán:**\n",
    "  1. Đọc tệp vào RDD.\n",
    "  2. `map` để đếm số lần xuất hiện của xâu trong mỗi dòng.\n",
    "  3. `reduce` để tính tổng số lần xuất hiện.\n",
    "- **Kết quả trả về:** Tổng số lần xâu xuất hiện."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "substring_to_count = \"xuân\"\n",
    "rdd_b2 = sc.textFile(\"phantichdulieu/HXH.txt\")\n",
    "counts_rdd = rdd_b2.map(lambda line: line.lower().count(substring_to_count.lower()))\n",
    "total_count = counts_rdd.reduce(lambda a, b: a + b)\n",
    "print(f\"Tổng số lần xuất hiện của xâu '{substring_to_count}' là: {total_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Giải thích kết quả**\n",
    "Kết quả cho biết tổng số lần từ \"xuân\" (không phân biệt hoa thường) xuất hiện trong toàn bộ văn bản."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Bài 3: Thống kê Bigram**\n",
    "\n",
    "**Các bước thực hiện:**\n",
    "- **Dữ liệu đầu vào:** Tệp `phantichdulieu/HXH.txt`.\n",
    "- **Các bước tính toán:**\n",
    "  1. Đọc tệp, tiền xử lý và tạo bigram.\n",
    "  2. Dùng `map` và `reduceByKey` để đếm tần suất.\n",
    "  3. Sắp xếp và lưu kết quả vào thư mục `HXH`.\n",
    "- **Kết quả trả về:** Thư mục `HXH` chứa kết quả."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"HXH\"\n",
    "if os.path.exists(output_dir):\n",
    "    shutil.rmtree(output_dir)\n",
    "\n",
    "rdd_b3 = sc.textFile(\"phantichdulieu/HXH.txt\")\n",
    "def create_bigrams(line):\n",
    "    clean_line = re.sub(r'[^a-zA-Záàảãạăắằẳẵặâấầẩẫậéèẻẽẹêếềểễệíìỉĩịóòỏõọôốồổỗộơớờởỡợúùủũụưứừửữựýỳỷỹỵđ\\s]', '', line.lower())\n",
    "    words = clean_line.split()\n",
    "    return [(words[i] + ' ' + words[i+1], 1) for i in range(len(words) - 1)] if len(words) >= 2 else []\n",
    "\n",
    "bigrams_rdd = rdd_b3.flatMap(create_bigrams)\n",
    "bigram_counts_rdd = bigrams_rdd.reduceByKey(lambda a, b: a + b)\n",
    "sorted_bigrams_rdd = bigram_counts_rdd.sortBy(lambda x: x[1], ascending=False)\n",
    "sorted_bigrams_rdd.saveAsTextFile(output_dir)\n",
    "print(f\"Đã thống kê và lưu kết quả vào thư mục '{output_dir}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Giải thích kết quả**\n",
    "Kết quả được lưu trong thư mục `HXH` dưới dạng các tệp `part-xxxxx`, chứa các cặp từ phổ biến nhất và tần suất của chúng."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Bài 4: Phân tích xếp hạng phim**\n",
    "---\n",
    "**Chuẩn bị dữ liệu cho Bài 4:**\n",
    "Đọc tệp `u.data` một lần và cache RDD để tái sử dụng cho tất cả các câu hỏi phụ, giúp tăng hiệu suất."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ratings_rdd = sc.textFile(\"phantichdulieu/u.data\")\n",
    "# Chuyển đổi mỗi dòng thành tuple (user, movie, rating)\n",
    "ratings_rdd = raw_ratings_rdd.map(lambda line: line.split('\\t')).map(lambda x: (x[0], x[1], int(x[2])))\n",
    "# Cache RDD để tăng tốc độ truy cập trong các câu sau\n",
    "ratings_rdd.cache()\n",
    "print(f\"Đã đọc và cache {ratings_rdd.count()} dòng dữ liệu ratings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.1 Đếm số bộ phim rating của mỗi người dùng**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ratings_count = ratings_rdd.map(lambda r: (r[0], 1)).reduceByKey(lambda a, b: a + b).sortBy(lambda x: x[1], ascending=False)\n",
    "print(\"Số lượng phim mỗi người dùng đã rating (10 người đầu tiên):\")\n",
    "for row in user_ratings_count.take(10):\n",
    "    print(f\"User: {row[0]}, Count: {row[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.2 Tính trung bình rating của mỗi người dùng**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_sum_count = ratings_rdd.map(lambda r: (r[0], (r[2], 1))).reduceByKey(lambda a, b: (a[0] + b[0], a[1] + b[1]))\n",
    "user_avg_rating = user_sum_count.mapValues(lambda v: v[0] / v[1]).sortBy(lambda x: x[1], ascending=False)\n",
    "print(\"Rating trung bình của mỗi người dùng (10 người đầu tiên):\")\n",
    "for row in user_avg_rating.take(10):\n",
    "    print(f\"User: {row[0]}, Average Rating: {row[1]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.3 Tính trung bình, cao nhất, thấp nhất rating cho mỗi bộ phim**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ratings = ratings_rdd.map(lambda r: (r[1], r[2])).groupByKey()\n",
    "movie_stats = movie_ratings.mapValues(lambda ratings: (sum(ratings)/len(ratings), max(ratings), min(ratings)))\n",
    "print(\"Thống kê rating (avg, max, min) cho mỗi phim (10 phim đầu tiên):\")\n",
    "for row in movie_stats.take(10):\n",
    "    print(f\"Movie: {row[0]}, Stats (Avg, Max, Min): ({row[1][0]:.2f}, {row[1][1]}, {row[1][2]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.4 Tìm những bộ phim rating chung của từng cặp người dùng**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_movies = ratings_rdd.map(lambda r: (r[0], r[1])).groupByKey().mapValues(set)\n",
    "user_pairs = user_movies.cartesian(user_movies).filter(lambda x: x[0][0] < x[1][0])\n",
    "common_movies = user_pairs.map(lambda x: ((x[0][0], x[1][0]), x[0][1].intersection(x[1][1])))\n",
    "print(\"Phim xem chung của từng cặp người dùng (5 cặp đầu tiên có phim chung):\")\n",
    "for row in common_movies.filter(lambda x: len(x[1]) > 0).take(5):\n",
    "    print(f\"Users: {row[0]}, Common Movies: {row[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.5 Tính độ tương tự Cosin giữa hai người dùng a và u (Sửa lỗi logic)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_a = '196'\n",
    "user_u = '186'\n",
    "\n",
    "# Lấy ratings của từng user dưới dạng (movie, rating)\n",
    "ratings_a = ratings_rdd.filter(lambda r: r[0] == user_a).map(lambda r: (r[1], r[2]))\n",
    "ratings_u = ratings_rdd.filter(lambda r: r[0] == user_u).map(lambda r: (r[1], r[2]))\n",
    "\n",
    "# Join để tìm các phim chung và cặp rating tương ứng (movie, (rating_a, rating_u))\n",
    "common_ratings_rdd = ratings_a.join(ratings_u)\n",
    "\n",
    "# Chỉ tính toán trên các phim chung\n",
    "numerator = common_ratings_rdd.map(lambda x: x[1][0] * x[1][1]).sum()\n",
    "denominator_a = math.sqrt(common_ratings_rdd.map(lambda x: x[1][0]**2).sum())\n",
    "denominator_u = math.sqrt(common_ratings_rdd.map(lambda x: x[1][1]**2).sum())\n",
    "\n",
    "cosine_similarity = 0\n",
    "if denominator_a > 0 and denominator_u > 0:\n",
    "    cosine_similarity = numerator / (denominator_a * denominator_u)\n",
    "\n",
    "print(f\"Độ tương tự Cosin (đã sửa) giữa user {user_a} và {user_u} là: {cosine_similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.6 Tính dự đoán rating của người dùng a cho bộ phim i (Sửa lỗi logic và hiệu năng)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_user = '1'\n",
    "target_movie = '3'\n",
    "similarity_threshold = 0.5\n",
    "\n",
    "# (user, (movie, rating))\n",
    "user_movie_ratings = ratings_rdd.map(lambda r: (r[0], (r[1], r[2])))\n",
    "\n",
    "# (movie, (user, rating))\n",
    "movie_user_ratings = ratings_rdd.map(lambda r: (r[1], (r[0], r[2])))\n",
    "\n",
    "# Lấy tất cả ratings của target_user\n",
    "target_user_ratings = user_movie_ratings.filter(lambda x: x[0] == target_user).values().collectAsMap()\n",
    "target_user_norm = math.sqrt(sum(rating**2 for rating in target_user_ratings.values()))\n",
    "\n",
    "# Broadcast biến này để các worker có thể truy cập hiệu quả\n",
    "b_target_user_ratings = sc.broadcast(target_user_ratings)\n",
    "b_target_user_norm = sc.broadcast(target_user_norm)\n",
    "\n",
    "# Nhóm ratings theo user: (user, {(movie, rating), ...})\n",
    "all_user_ratings_grouped = user_movie_ratings.groupByKey().mapValues(list)\n",
    "\n",
    "# Tính Cosine Similarity cho tất cả user với target_user\n",
    "def calculate_similarity(user_data):\n",
    "    user_id, ratings_list = user_data\n",
    "    if user_id == target_user: return (user_id, (0, 0)) # Bỏ qua chính target_user\n",
    "\n",
    "    # Lấy dữ liệu từ broadcast variable\n",
    "    t_ratings = b_target_user_ratings.value\n",
    "    t_norm = b_target_user_norm.value\n",
    "\n",
    "    numerator = 0\n",
    "    common_ratings_norm_sq = 0\n",
    "    for movie, rating in ratings_list:\n",
    "        if movie in t_ratings:\n",
    "            numerator += rating * t_ratings[movie]\n",
    "            common_ratings_norm_sq += rating**2\n",
    "    \n",
    "    u_norm = math.sqrt(common_ratings_norm_sq)\n",
    "\n",
    "    similarity = 0\n",
    "    if t_norm > 0 and u_norm > 0:\n",
    "        similarity = numerator / (t_norm * u_norm)\n",
    "    \n",
    "    # Trả về (user_id, (similarity, rating cho target_movie nếu có))\n",
    "    rating_for_target_movie = 0\n",
    "    for movie, rating in ratings_list:\n",
    "        if movie == target_movie:\n",
    "            rating_for_target_movie = rating\n",
    "            break\n",
    "            \n",
    "    return (user_id, (similarity, rating_for_target_movie))\n",
    "\n",
    "similarities_rdd = all_user_ratings_grouped.map(calculate_similarity)\n",
    "\n",
    "# Lọc những user có độ tương tự cao và đã rate target_movie\n",
    "similar_users_rdd = similarities_rdd.filter(lambda x: x[1][0] >= similarity_threshold and x[1][1] > 0)\n",
    "\n",
    "# Tính toán tử số và mẫu số cho công thức dự đoán\n",
    "prediction_numerator = similar_users_rdd.map(lambda x: x[1][0] * x[1][1]).sum()\n",
    "prediction_denominator = similar_users_rdd.map(lambda x: abs(x[1][0])).sum()\n",
    "\n",
    "predicted_rating = 0\n",
    "if prediction_denominator > 0:\n",
    "    predicted_rating = prediction_numerator / prediction_denominator\n",
    "\n",
    "print(f\"Rating dự đoán (đã sửa) của user {target_user} cho phim {target_movie} là: {predicted_rating:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Dọn dẹp môi trường**\n",
    "Dừng SparkSession để giải phóng tài nguyên."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}